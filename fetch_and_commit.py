# fetch_and_commit.py

import os
import sys
import json
import requests
import gzip
import re
import argparse
import hashlib
from datetime import datetime, timezone
from pathlib import Path
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import partial
from collections import defaultdict

# --- –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ ---
try:
    from lxml import etree
except ImportError:
    sys.exit("–û—à–∏–±–∫–∞: lxml –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install lxml")

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
MAX_WORKERS = 100
SOURCES_FILE = 'sources.json'
DATA_DIR = Path('data')
ICONS_DIR = Path('icons')
ICONS_MAP_FILE = Path('icons_map.json')
README_FILE = 'README.md'
RAW_BASE_URL = "https://raw.githubusercontent.com/{owner}/{repo}/main/{filepath}"

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def is_gzipped(file_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª gzipped."""
    with open(file_path, 'rb') as f:
        return f.read(2) == b'\x1f\x8b'

class CustomEncoder(json.JSONEncoder):
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Path –æ–±—ä–µ–∫—Ç–æ–≤ –∏ –º–Ω–æ–∂–µ—Å—Ç–≤ –≤ JSON."""
    def default(self, obj):
        if isinstance(obj, Path):
            return str(obj).replace('\\', '/') # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Windows
        if isinstance(obj, set):
            return list(obj)
        return json.JSONEncoder.default(self, obj)

# --- –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def read_sources_and_notes():
    """–ß–∏—Ç–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –∑–∞–º–µ—Ç–∫–∏ –∏–∑ sources.json."""
    try:
        with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
            sources, notes = config.get('sources', []), config.get('notes', '')
            if not sources:
                sys.exit("–û—à–∏–±–∫–∞: –≤ sources.json –Ω–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.")
            return sources, notes
    except Exception as e:
        sys.exit(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {SOURCES_FILE}: {e}")

def clear_directory(dir_path: Path):
    """–û—á–∏—â–∞–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –æ—Ç —Ñ–∞–π–ª–æ–≤ –∏ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
    if dir_path.exists():
        for item in dir_path.iterdir():
            if item.is_dir():
                clear_directory(item)
                item.rmdir()
            else:
                item.unlink()
    else:
        dir_path.mkdir(parents=True, exist_ok=True)

def download_one(entry):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–∏–Ω EPG —Ñ–∞–π–ª."""
    url, desc = entry['url'], entry['desc']
    temp_path = DATA_DIR / ("tmp_" + os.urandom(4).hex())
    result = {'entry': entry, 'error': None}
    try:
        print(f"–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É: {desc} ({url})")
        with requests.get(url, stream=True, timeout=120) as r:
            r.raise_for_status()
            with open(temp_path, 'wb') as f:
                for chunk in r.iter_content(16 * 1024):
                    f.write(chunk)
        size_bytes = temp_path.stat().st_size
        if size_bytes == 0:
            raise ValueError("–§–∞–π–ª –ø—É—Å—Ç–æ–π.")
        result.update({'size_mb': round(size_bytes / (1024 * 1024), 2), 'temp_path': temp_path})
        return result
    except Exception as e:
        result['error'] = f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}"
        print(f"–û—à–∏–±–∫–∞ –¥–ª—è {desc}: {result['error']}")
        if temp_path.exists():
            temp_path.unlink()
    return result

def download_icon(session, url, save_path):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω—É –∏–∫–æ–Ω–∫—É."""
    try:
        # –°–æ–∑–¥–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with session.get(url, stream=True, timeout=30) as r:
            r.raise_for_status()
            with open(save_path, 'wb') as f:
                for chunk in r.iter_content(8192):
                    f.write(chunk)
        return True
    except requests.RequestException:
        return False

def get_icon_signature(file_path):
    """–°–æ–∑–¥–∞–µ—Ç '—Å–∏–≥–Ω–∞—Ç—É—Ä—É' EPG-—Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ URL-–æ–≤ –µ–≥–æ –∏–∫–æ–Ω–æ–∫."""
    icon_urls = set()
    try:
        open_func = gzip.open if is_gzipped(file_path) else open
        with open_func(file_path, 'rb') as f:
            for _, element in etree.iterparse(f, tag='icon', events=('end',)):
                if 'src' in element.attrib:
                    icon_urls.add(element.attrib['src'])
                element.clear()
        
        if not icon_urls:
            return None
            
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º URL –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ö—ç—à–∞
        sorted_urls = sorted(list(icon_urls))
        return hashlib.sha256(''.join(sorted_urls).encode('utf-8')).hexdigest()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –¥–ª—è {file_path.name}: {e}", file=sys.stderr)
        return None

def perform_full_update(download_results):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏, —Å–∫–∞—á–∏–≤–∞–µ—Ç –∏–∫–æ–Ω–∫–∏, —Å–æ–∑–¥–∞–µ—Ç –∫–∞—Ä—Ç—É."""
    print("\n--- –≠—Ç–∞–ø 1: –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ –Ω–∞–±–æ—Ä–∞–º –∏–∫–æ–Ω–æ–∫ ---")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ —Å–∏–≥–Ω–∞—Ç—É—Ä–µ –∏–∫–æ–Ω–æ–∫
    groups = defaultdict(list)
    for res in download_results:
        if not res.get('error'):
            signature = get_icon_signature(res['temp_path'])
            # –ï—Å–ª–∏ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –Ω–µ—Ç (–Ω–µ—Ç –∏–∫–æ–Ω–æ–∫), –∏—Å—Ç–æ—á–Ω–∏–∫ –±—É–¥–µ—Ç –≤ –≥—Ä—É–ø–ø–µ None
            groups[signature].append(res)
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(groups)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä—É–ø–ø –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (–≤–∫–ª—é—á–∞—è –≥—Ä—É–ø–ø—É –±–µ–∑ –∏–∫–æ–Ω–æ–∫).")

    icon_data = {
        "groups": {},
        "source_to_group": {}
    }
    urls_to_download = {}

    print("\n--- –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç –∏–∫–æ–Ω–æ–∫ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∑–∞–≥—Ä—É–∑–∫–µ ---")
    for signature, sources_in_group in groups.items():
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≥—Ä—É–ø–ø—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –±–µ–∑ –∏–∫–æ–Ω–æ–∫
        if signature is None:
            for res in sources_in_group:
                icon_data["source_to_group"][res['entry']['url']] = None
            continue
        
        group_id = signature[:12]
        group_icon_dir = ICONS_DIR / f"group_{group_id}"
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è ID –∫–∞–Ω–∞–ª–∞ -> –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
        icon_map_for_group = {}
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª –∏–∑ –≥—Ä—É–ø–ø—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞, —Ç.–∫. –Ω–∞–±–æ—Ä—ã –∏–∫–æ–Ω–æ–∫ —É –Ω–∏—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
        representative_file = sources_in_group[0]['temp_path']
        
        try:
            open_func = gzip.open if is_gzipped(representative_file) else open
            with open_func(representative_file, 'rb') as f:
                for _, channel in etree.iterparse(f, tag='channel', events=('end',)):
                    channel_id = channel.get('id')
                    icon_tag = channel.find('icon')
                    if channel_id and icon_tag is not None and 'src' in icon_tag.attrib:
                        icon_url = icon_tag.get('src')
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL –∏–ª–∏ ID –∫–∞–Ω–∞–ª–∞
                        filename = Path(urlparse(icon_url).path).name or f"{channel_id}.png"
                        local_path = group_icon_dir / filename
                        icon_map_for_group[channel_id] = local_path
                        urls_to_download[icon_url] = local_path
                    channel.clear()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞-–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—è {representative_file.name}: {e}", file=sys.stderr)
            continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç—É –≥—Ä—É–ø–ø—É, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥—Ä—É–ø–ø–µ
        icon_data["groups"][signature] = {
            "icon_dir": group_icon_dir,
            "icon_map": icon_map_for_group
        }
        for res in sources_in_group:
            icon_data["source_to_group"][res['entry']['url']] = signature
            
        print(f"–ì—Ä—É–ø–ø–∞ {group_id}: {len(sources_in_group)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, {len(icon_map_for_group)} –∏–∫–æ–Ω–æ–∫.")

    # –°–∫–∞—á–∏–≤–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∫–æ–Ω–∫–∏
    print(f"\n–¢—Ä–µ–±—É–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å {len(urls_to_download)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∫–æ–Ω–æ–∫.")
    if urls_to_download:
        adapter = requests.adapters.HTTPAdapter(pool_connections=MAX_WORKERS, pool_maxsize=MAX_WORKERS)
        with requests.Session() as session:
            session.mount('http://', adapter)
            session.mount('https://', adapter)
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                downloader = partial(download_icon, session)
                future_to_url = {executor.submit(downloader, url, path): url for url, path in urls_to_download.items()}
                for future in as_completed(future_to_url):
                    future.result()
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∫–æ–Ω–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ä—Ç—É
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞—Ä—Ç—ã –∏–∫–æ–Ω–æ–∫ –≤ {ICONS_MAP_FILE}...")
    with open(ICONS_MAP_FILE, 'w', encoding='utf-8') as f:
        json.dump(icon_data, f, ensure_ascii=False, indent=2, cls=CustomEncoder)
    print("–ö–∞—Ä—Ç–∞ –∏–∫–æ–Ω–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
    
    return icon_data

def load_icon_data_for_daily_update():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–∞—Ä—Ç—É –∏–∫–æ–Ω–æ–∫ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è."""
    print("\n--- –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–∞—Ä—Ç—ã –∏–∫–æ–Ω–æ–∫ ---")
    if not ICONS_MAP_FILE.is_file():
        print(f"–§–∞–π–ª {ICONS_MAP_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò–∫–æ–Ω–∫–∏ –Ω–µ –±—É–¥—É—Ç –∑–∞–º–µ–Ω–µ–Ω—ã.")
        print("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (`--full-update`) –¥–ª—è –µ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è.")
        return None
    try:
        with open(ICONS_MAP_FILE, 'r', encoding='utf-8') as f:
            icon_data = json.load(f)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ø—É—Ç–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ Path –æ–±—ä–µ–∫—Ç—ã –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        for group in icon_data.get('groups', {}).values():
            if 'icon_map' in group:
                group['icon_map'] = {k: Path(v) for k, v in group['icon_map'].items()}
        
        print(f"–ö–∞—Ä—Ç–∞ –∏–∫–æ–Ω–æ–∫ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ì—Ä—É–ø–ø: {len(icon_data.get('groups', {}))}.")
        return icon_data
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ {ICONS_MAP_FILE}: {e}", file=sys.stderr)
        return None

def process_epg_file(file_path, icon_sub_map, owner, repo_name, entry):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω EPG-—Ñ–∞–π–ª, –∑–∞–º–µ–Ω—è—è URL –∏–∫–æ–Ω–æ–∫ –ø–æ —Ç–æ—á–Ω–æ–π –∫–∞—Ä—Ç–µ."""
    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª: {file_path.name} –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {entry['desc']}")
    if not icon_sub_map:
        print(f"–î–ª—è {file_path.name} –Ω–µ—Ç –∫–∞—Ä—Ç—ã –∏–∫–æ–Ω–æ–∫. –ü—Ä–æ–ø—É—Å–∫–∞—é –∑–∞–º–µ–Ω—É.")
        return True

    try:
        was_gzipped = is_gzipped(file_path)
        open_func = gzip.open if was_gzipped else open
        parser = etree.XMLParser(remove_blank_text=True)
        with open_func(file_path, 'rb') as f:
            tree = etree.parse(f, parser)
        root = tree.getroot()
        
        changes_made = 0
        for channel in root.findall('channel'):
            channel_id = channel.get('id')
            # –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ ID –∫–∞–Ω–∞–ª–∞ –≤ –∫–∞—Ä—Ç–µ –¥–ª—è –¥–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø—ã
            matched_icon_path = icon_sub_map.get(channel_id)
            
            if matched_icon_path:
                new_icon_url = RAW_BASE_URL.format(owner=owner, repo=repo_name, filepath=str(matched_icon_path).replace('\\', '/'))
                icon_tag = channel.find('icon')
                if icon_tag is None:
                    icon_tag = etree.SubElement(channel, 'icon')
                
                if icon_tag.get('src') != new_icon_url:
                    icon_tag.set('src', new_icon_url)
                    changes_made += 1
        
        if changes_made > 0:
            print(f"–í–Ω–µ—Å–µ–Ω–æ {changes_made} –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∏–∫–æ–Ω–∫–∏ —Ñ–∞–π–ª–∞ {file_path.name}.")
            doctype_str = '<!DOCTYPE tv SYSTEM "https://iptvx.one/xmltv.dtd">'
            xml_bytes = etree.tostring(tree, pretty_print=True, xml_declaration=True, encoding='UTF-8', doctype=doctype_str)
            
            original_filename = Path(urlparse(entry['url']).path).name
            if original_filename.lower().endswith('.gz'):
                archive_internal_name = original_filename[:-3]
            else:
                archive_internal_name = f"{original_filename}.xml"
            
            if was_gzipped:
                with gzip.GzipFile(filename=archive_internal_name, mode='wb', fileobj=open(file_path, 'wb'), mtime=0) as f_out:
                    f_out.write(xml_bytes)
            else:
                with open(file_path, 'wb') as f_out:
                    f_out.write(xml_bytes)
        else:
            print(f"–ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∏–∫–æ–Ω–∫–∞—Ö –¥–ª—è {file_path.name} –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        
        return True
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}", file=sys.stderr)
        return False

def update_readme(results, notes):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç README.md —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è."""
    timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M %Z')
    lines = [notes, "\n---"] if notes else []
    lines.append(f"\n# –û–±–Ω–æ–≤–ª–µ–Ω–æ: {timestamp}\n")
    
    for idx, r in enumerate(results, 1):
        lines.append(f"### {idx}. {r['entry']['desc']}\n")
        if r.get('error'):
            lines.extend([f"**–°—Ç–∞—Ç—É—Å:** üî¥ –û—à–∏–±–∫–∞", f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{r['entry']['url']}`", f"**–ü—Ä–∏—á–∏–Ω–∞:** {r.get('error')}", "---"])
        else:
            lines.extend([f"**–†–∞–∑–º–µ—Ä:** {r['size_mb']} MB", "", "**–°—Å—ã–ª–∫–∞ –¥–ª—è –ø–ª–µ–µ—Ä–∞ (GitHub Raw):**", f"`{r['raw_url']}`", "---"])
    
    with open(README_FILE, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
    print(f"\nREADME.md –æ–±–Ω–æ–≤–ª—ë–Ω ({len(results)} –∑–∞–ø–∏—Å–µ–π).")

def main():
    parser = argparse.ArgumentParser(description="EPG Updater Script")
    parser.add_argument('--full-update', action='store_true', help='Perform a full update, including icons and icon map.')
    args = parser.parse_args()

    repo = os.getenv('GITHUB_REPOSITORY')
    if not repo or '/' not in repo:
        sys.exit("–û—à–∏–±–∫–∞: –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è GITHUB_REPOSITORY –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞.")
    owner, repo_name = repo.split('/')
    
    sources, notes = read_sources_and_notes()
    
    print("\n--- –≠—Ç–∞–ø 0: –ó–∞–≥—Ä—É–∑–∫–∞ EPG —Ñ–∞–π–ª–æ–≤ ---")
    clear_directory(DATA_DIR)
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        download_results = list(executor.map(download_one, sources))

    icon_data = None
    if args.full_update:
        print("\n–ó–∞–ø—É—â–µ–Ω —Ä–µ–∂–∏–º –ü–û–õ–ù–û–ì–û –û–ë–ù–û–í–õ–ï–ù–ò–Ø.")
        clear_directory(ICONS_DIR)
        icon_data = perform_full_update(download_results)
    else:
        print("\n–ó–∞–ø—É—â–µ–Ω —Ä–µ–∂–∏–º –ï–ñ–ï–î–ù–ï–í–ù–û–ì–û –û–ë–ù–û–í–õ–ï–ù–ò–Ø.")
        icon_data = load_icon_data_for_daily_update()

    print("\n--- –≠—Ç–∞–ø 3: –ó–∞–º–µ–Ω–∞ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏–∫–æ–Ω–∫–∏ –≤ EPG —Ñ–∞–π–ª–∞—Ö ---")
    if icon_data:
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = []
            for res in download_results:
                if res.get('error'): continue
                
                source_url = res['entry']['url']
                group_hash = icon_data['source_to_group'].get(source_url)
                
                icon_sub_map = {}
                if group_hash:
                    icon_sub_map = icon_data['groups'][group_hash].get('icon_map', {})
                
                futures.append(executor.submit(process_epg_file, res['temp_path'], icon_sub_map, owner, repo_name, res['entry']))
            
            for future in as_completed(futures):
                future.result()
    else:
        print("–î–∞–Ω–Ω—ã–µ –æ–± –∏–∫–æ–Ω–∫–∞—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, –∑–∞–º–µ–Ω–∞ —Å—Å—ã–ª–æ–∫ –ø—Ä–æ–ø—É—â–µ–Ω–∞.")

    print("\n--- –≠—Ç–∞–ø 4: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ README ---")
    url_to_result = {res['entry']['url']: res for res in download_results}
    ordered_results = [url_to_result[s['url']] for s in sources]
    final_results, used_names = [], set()

    for res in ordered_results:
        if res.get('error'):
            final_results.append(res)
            continue
            
        final_filename_from_url = Path(urlparse(res['entry']['url']).path).name
        # –î–ª—è URL –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (—Ç–∏–ø–∞ EPG_LITE) –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if not Path(final_filename_from_url).suffix:
            ext = '.xml.gz' if is_gzipped(res['temp_path']) else '.xml'
            proposed_filename = f"{final_filename_from_url}{ext}"
        else:
            proposed_filename = final_filename_from_url

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
        final_name, counter = proposed_filename, 1
        while final_name in used_names:
            p_stem = Path(proposed_filename).stem
            p_suffixes = "".join(Path(proposed_filename).suffixes)
            final_name = f"{p_stem}-{counter}{p_suffixes}"
            counter += 1
        used_names.add(final_name)
        
        target_path = DATA_DIR / final_name
        res['temp_path'].rename(target_path)
        res['raw_url'] = RAW_BASE_URL.format(owner=owner, repo=repo_name, filepath=str(target_path).replace('\\', '/'))
        final_results.append(res)

    update_readme(final_results, notes)
    print("\n–°–∫—Ä–∏–ø—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")

if __name__ == '__main__':
    main()
