# fetch_and_commit.py

import os
import sys
import json
import requests
import gzip
import re
from datetime import datetime, timezone
from pathlib import Path
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import partial

# –ò—Å–ø–æ–ª—å–∑—É–µ–º lxml –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
try:
    from lxml import etree
except ImportError:
    print("–û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ lxml –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ: pip install lxml", file=sys.stderr)
    sys.exit(1)

# –ò—Å–ø–æ–ª—å–∑—É–µ–º thefuzz –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç—Ä–æ–∫
try:
    from thefuzz import fuzz
except ImportError:
    print("–û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ thefuzz –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ: pip install thefuzz python-Levenshtein", file=sys.stderr)
    sys.exit(1)

import gdshortener

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò ---
# GitHub Actions runner –∏–º–µ–µ—Ç 2 CPU, –Ω–æ –º–Ω–æ–≥–æ I/O, —Å—Ç–∞–≤–∏–º –±–æ–ª—å—à–µ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Å–µ—Ç–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
MAX_WORKERS = 50
# –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–∞–Ω–∞–ª–æ–≤ (80%)
SIMILARITY_THRESHOLD = 80 # thefuzz –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —à–∫–∞–ª—É 0-100

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
SOURCES_FILE = 'sources.json'
DATA_DIR = Path('data')
ICONS_DIR = Path('icons')
README_FILE = 'README.md'
CHUNK_SIZE = 16 * 1024
MAX_FILE_SIZE_MB = 95
JSDELIVR_SIZE_LIMIT_MB = 20

RAW_BASE_URL = "https://raw.githubusercontent.com/{owner}/{repo}/main/{filepath}"
JSDELIVR_BASE_URL = "https://cdn.jsdelivr.net/gh/{owner}/{repo}@main/{filepath}"

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def clean_name(name):
    """–û—á–∏—â–∞–µ—Ç –∏–º—è –∫–∞–Ω–∞–ª–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
    name = name.lower()
    name = re.sub(r'\s*\b(hd|fhd|uhd|4k|8k|sd|low|vip|\(p\))\b', '', name, flags=re.IGNORECASE)
    name = re.sub(r'\[.*?\]|\(.*?\)', '', name)
    name = re.sub(r'[^\w\s]', '', name)
    return ' '.join(name.split())

def get_channel_names(channel_element):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –æ—á–∏—â–∞–µ—Ç –≤—Å–µ display-name –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞ channel."""
    names = [el.text for el in channel_element.findall('display-name')]
    return {clean_name(name) for name in names if name}

def is_gzipped(file_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª gzipped, –ø–æ –µ–≥–æ –º–∞–≥–∏—á–µ—Å–∫–∏–º –±–∞–π—Ç–∞–º."""
    with open(file_path, 'rb') as f:
        return f.read(2) == b'\x1f\x8b'

# --- –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def read_sources_and_notes():
    # ... (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    try:
        with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
            sources = config.get('sources', [])
            notes = config.get('notes', '')
            if not sources:
                print("–û—à–∏–±–∫–∞: –≤ sources.json –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤ –∫–ª—é—á–µ 'sources'.", file=sys.stderr)
                sys.exit(1)
            for s in sources:
                s.setdefault('ico_src', False)
            return sources, notes
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {SOURCES_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω.", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"–û—à–∏–±–∫–∞: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON –≤ —Ñ–∞–π–ª–µ {SOURCES_FILE}.", file=sys.stderr)
        sys.exit(1)


def clear_dirs():
    # ... (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    for d in [DATA_DIR, ICONS_DIR]:
        if d.exists():
            for f in d.iterdir():
                if f.is_file(): f.unlink()
        else:
            d.mkdir(parents=True, exist_ok=True)
    gitignore = ICONS_DIR / '.gitignore'
    if not gitignore.exists():
        gitignore.write_text('*\n!.gitignore')


def download_one(entry):
    # ... (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    url = entry['url']
    desc = entry['desc']
    temp_path = DATA_DIR / ("tmp_" + os.urandom(4).hex())
    result = {'entry': entry, 'error': None}
    try:
        print(f"–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É: {desc} ({url})")
        with requests.get(url, stream=True, timeout=120) as r:
            r.raise_for_status()
            with open(temp_path, 'wb') as f:
                for chunk in r.iter_content(CHUNK_SIZE):
                    f.write(chunk)
        size_bytes = temp_path.stat().st_size
        size_mb = round(size_bytes / (1024 * 1024), 2)
        if size_bytes == 0: raise ValueError("–§–∞–π–ª –ø—É—Å—Ç–æ–π.")
        if size_bytes > MAX_FILE_SIZE_MB * 1024 * 1024: raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({size_mb} MB > {MAX_FILE_SIZE_MB} MB).")
        result.update({'size_mb': size_mb, 'temp_path': temp_path})
        return result
    except Exception as e:
        result['error'] = f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}"
        print(f"–û—à–∏–±–∫–∞ –¥–ª—è {desc}: {result['error']}")
        if temp_path.exists(): temp_path.unlink()
    return result


def download_icon(session, url, save_path):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω—É –∏–∫–æ–Ω–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –æ–±—â—É—é —Å–µ—Å—Å–∏—é."""
    try:
        with session.get(url, stream=True, timeout=30) as r:
            r.raise_for_status()
            with open(save_path, 'wb') as f:
                for chunk in r.iter_content(8192):
                    f.write(chunk)
        return True
    except requests.RequestException as e:
        # –ù–µ –≤—ã–≤–æ–¥–∏–º –æ—à–∏–±–∫—É –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∫–æ–Ω–∫–∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –ª–æ–≥
        # print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∫–æ–Ω–∫—É {url}: {e}", file=sys.stderr)
        return False

def _parse_icon_source_file(file_path, desc):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω EPG —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏–∫–æ–Ω–æ–∫. –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏—è."""
    print(f"–°–∫–∞–Ω–∏—Ä—É—é –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∫–æ–Ω–æ–∫: {desc}")
    found_icons = []
    try:
        open_func = gzip.open if is_gzipped(file_path) else open
        with open_func(file_path, 'rb') as f:
            tree = etree.parse(f)
        root = tree.getroot()

        for channel in root.findall('channel'):
            channel_id = channel.get('id')
            icon_tag = channel.find('icon')
            if channel_id and icon_tag is not None and 'src' in icon_tag.attrib:
                icon_url = icon_tag.get('src')
                names = get_channel_names(channel)
                if names and icon_url:
                    found_icons.append((desc, channel_id, names, icon_url))
    except (etree.XMLSyntaxError, gzip.BadGzipFile, ValueError) as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {file_path.name} –¥–ª—è —Å–±–æ—Ä–∞ –∏–∫–æ–Ω–æ–∫: {e}", file=sys.stderr)
    return found_icons

def build_icon_database(download_results):
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç EPG-–∏—Å—Ç–æ—á–Ω–∏–∫–∏, —Å–∫–∞—á–∏–≤–∞–µ—Ç –∏–∫–æ–Ω–∫–∏ –∏ —Å–æ–∑–¥–∞–µ—Ç –±–∞–∑—É. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ."""
    print("\n--- –≠—Ç–∞–ø 1: –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∫–æ–Ω–æ–∫ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥) ---")
    icon_db = {}
    icon_urls_to_download = {}
    
    # –†–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ XML-—Ñ–∞–π–ª–æ–≤
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = []
        for result in download_results:
            if not result.get('error') and result['entry']['ico_src']:
                futures.append(executor.submit(_parse_icon_source_file, result['temp_path'], result['entry']['desc']))

        for future in as_completed(futures):
            for desc, channel_id, names, icon_url in future.result():
                parsed_url = urlparse(icon_url)
                filename = Path(parsed_url.path).name or f"{channel_id}.png"
                local_icon_path = ICONS_DIR / filename
                db_key = f"{desc}_{channel_id}"
                icon_db[db_key] = {'icon_path': local_icon_path, 'names': names}
                # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                icon_urls_to_download[icon_url] = local_icon_path
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(icon_db)} –∫–∞–Ω–∞–ª–æ–≤ —Å –∏–∫–æ–Ω–∫–∞–º–∏ –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö.")
    print(f"–¢—Ä–µ–±—É–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å {len(icon_urls_to_download)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∫–æ–Ω–æ–∫.")
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∫–æ–Ω–æ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏
    with requests.Session() as session:
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º partial, —á—Ç–æ–±—ã –ø–µ—Ä–µ–¥–∞—Ç—å —Å–µ—Å—Å–∏—é –≤ –∫–∞–∂–¥—ã–π –≤—ã–∑–æ–≤
            downloader = partial(download_icon, session)
            future_to_url = {executor.submit(downloader, url, path): url for url, path in icon_urls_to_download.items()}
            
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä, –Ω–æ –≤ CI —ç—Ç–æ –ª–∏—à–Ω–µ–µ
            for future in as_completed(future_to_url):
                future.result()

    print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∫–æ–Ω–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    return icon_db


def find_best_match(channel_names, icon_db):
    """–ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∏–∫–æ–Ω–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –±—ã—Å—Ç—Ä—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É thefuzz."""
    if not channel_names: return None
        
    best_match_score = 0
    best_match_path = None

    for db_entry in icon_db.values():
        db_names = db_entry['names']
        if not db_names: continue
        
        if channel_names & db_names:
            return db_entry['icon_path']

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º fuzz.token_set_ratio, –æ–Ω —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–∞–∑–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º —Å–ª–æ–≤ –∏ –ª–∏—à–Ω–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
        score = fuzz.token_set_ratio(' '.join(sorted(list(channel_names))), ' '.join(sorted(list(db_names))))
        
        if score > best_match_score:
            best_match_score = score
            best_match_path = db_entry['icon_path']
            
    if best_match_score >= SIMILARITY_THRESHOLD:
        return best_match_path
        
    return None

def process_epg_file(file_path, icon_db, owner, repo_name):
    # ... (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª: {file_path.name}")
    try:
        was_gzipped = is_gzipped(file_path)
        open_func = gzip.open if was_gzipped else open
        parser = etree.XMLParser(remove_blank_text=True)
        with open_func(file_path, 'rb') as f:
            tree = etree.parse(f, parser)
        root = tree.getroot()
        changes_made = 0
        for channel in root.findall('channel'):
            channel_names = get_channel_names(channel)
            matched_icon_path = find_best_match(channel_names, icon_db)
            if matched_icon_path:
                new_icon_url = RAW_BASE_URL.format(owner=owner, repo=repo_name, filepath=matched_icon_path.as_posix())
                icon_tag = channel.find('icon')
                if icon_tag is None:
                    icon_tag = etree.SubElement(channel, 'icon')
                if icon_tag.get('src') != new_icon_url:
                    icon_tag.set('src', new_icon_url)
                    changes_made += 1
        if changes_made > 0:
            print(f"–í–Ω–µ—Å–µ–Ω–æ {changes_made} –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∏–∫–æ–Ω–∫–∏ —Ñ–∞–π–ª–∞ {file_path.name}.")
            doctype_str = '<!DOCTYPE tv SYSTEM "https://iptvx.one/xmltv.dtd">'
            if was_gzipped:
                with gzip.open(file_path, 'wb') as f_out:
                    f_out.write(etree.tostring(tree, pretty_print=True, xml_declaration=True, encoding='UTF-8', doctype=doctype_str))
            else:
                tree.write(str(file_path), pretty_print=True, xml_declaration=True, encoding='UTF-8', doctype=doctype_str)
        return True
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}", file=sys.stderr)
        return False

def shorten_url_safely(url):
    # ... (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    try:
        shortener = gdshortener.ISGDShortener()
        short_tuple = shortener.shorten(url)
        return short_tuple[0] if short_tuple and short_tuple[0] else "–Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∫—Ä–∞—Ç–∏—Ç—å"
    except Exception as e:
        # print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∫—Ä–∞—Ç–∏—Ç—å URL {url}: {e}", file=sys.stderr)
        return "–Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∫—Ä–∞—Ç–∏—Ç—å"

def update_readme(results, notes):
    # ... (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    utc_now = datetime.now(timezone.utc)
    timestamp = utc_now.strftime('%Y-%m-%d %H:%M %Z')
    lines = []
    if notes: lines.extend([notes, "\n---"])
    lines.append(f"\n# –û–±–Ω–æ–≤–ª–µ–Ω–æ: {timestamp}\n")
    for idx, r in enumerate(results, 1):
        lines.append(f"### {idx}. {r['entry']['desc']}")
        lines.append("")
        if r.get('error'):
            lines.extend([f"**–°—Ç–∞—Ç—É—Å:** üî¥ –û—à–∏–±–∫–∞", f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{r['entry']['url']}`", f"**–ü—Ä–∏—á–∏–Ω–∞:** {r.get('error')}"])
        else:
            lines.extend([f"**–†–∞–∑–º–µ—Ä:** {r['size_mb']} MB", "", f"**–û—Å–Ω–æ–≤–Ω–∞—è —Å—Å—ã–ª–∫–∞ (GitHub Raw):**", f"`{r['raw_url']}`", "", "> **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å—Å—ã–ª–∫–∏:**", ">", f"> - *–ö–æ—Ä–æ—Ç–∫–∞—è (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–ª–µ–µ—Ä—ã –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç):* `{r['short_raw_url']}`"])
            if r.get('jsdelivr_url'):
                lines.append(f"> - *CDN (jsDelivr):* `{r['jsdelivr_url']}` (–ö–æ—Ä–æ—Ç–∫–∞—è (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–ª–µ–µ—Ä—ã –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç): `{r['short_jsdelivr_url']}`)")
        lines.append("\n---")
    with open(README_FILE, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
    print(f"README.md –æ–±–Ω–æ–≤–ª—ë–Ω ({len(results)} –∑–∞–ø–∏—Å–µ–π)")


def main():
    repo = os.getenv('GITHUB_REPOSITORY')
    if not repo or '/' not in repo:
        print("–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å GITHUB_REPOSITORY.", file=sys.stderr)
        sys.exit(1)
    
    owner, repo_name = repo.split('/')
    
    sources, notes = read_sources_and_notes()
    clear_dirs()

    # --- –≠—Ç–∞–ø 0: –ó–∞–≥—Ä—É–∑–∫–∞ EPG ---
    print("\n--- –≠—Ç–∞–ø 0: –ó–∞–≥—Ä—É–∑–∫–∞ EPG —Ñ–∞–π–ª–æ–≤ ---")
    download_results = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_entry = {executor.submit(download_one, entry): entry for entry in sources}
        for future in as_completed(future_to_entry):
            download_results.append(future.result())

    # --- –≠—Ç–∞–ø 1: –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∏–∫–æ–Ω–æ–∫ ---
    icon_db = build_icon_database(download_results)
    
    # --- –≠—Ç–∞–ø 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ EPG —Ñ–∞–π–ª–æ–≤ ---
    print("\n--- –≠—Ç–∞–ø 2: –ó–∞–º–µ–Ω–∞ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏–∫–æ–Ω–∫–∏ –≤ EPG —Ñ–∞–π–ª–∞—Ö ---")
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = []
        for res in download_results:
            if not res.get('error'):
                futures.append(executor.submit(process_epg_file, res['temp_path'], icon_db, owner, repo_name))
        for future in as_completed(futures):
            future.result()
    
    # --- –≠—Ç–∞–ø 3: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ README ---
    # ... (–∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    print("\n--- –≠—Ç–∞–ø 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –∏ README.md ---")
    url_to_result = {res['entry']['url']: res for res in download_results}
    ordered_results = [url_to_result[s['url']] for s in sources]
    final_results = []
    used_names = set()
    for res in ordered_results:
        if res.get('error'):
            final_results.append(res)
            continue
        true_extension = '.xml.gz' if is_gzipped(res['temp_path']) else '.xml'
        filename_from_url = Path(urlparse(res['entry']['url']).path).name or "download"
        base_name = filename_from_url.split('.')[0]
        proposed_filename = f"{base_name}{true_extension}"
        final_name = proposed_filename
        counter = 1
        while final_name in used_names:
            p = Path(proposed_filename)
            stem = p.name.replace(''.join(p.suffixes), '')
            final_name = f"{stem}-{counter}{''.join(p.suffixes)}"
            counter += 1
        used_names.add(final_name)
        target_path = DATA_DIR / final_name
        res['temp_path'].rename(target_path)
        raw_url = RAW_BASE_URL.format(owner=owner, repo=repo_name, filepath=target_path.as_posix())
        res['raw_url'] = raw_url
        res['short_raw_url'] = shorten_url_safely(raw_url)
        if res['size_mb'] < JSDELIVR_SIZE_LIMIT_MB:
            jsdelivr_url = JSDELIVR_BASE_URL.format(owner=owner, repo=repo_name, filepath=target_path.as_posix())
            res['jsdelivr_url'] = shorten_url_safely(jsdelivr_url)
        final_results.append(res)

    update_readme(final_results, notes)
    print("\n–°–∫—Ä–∏–ø—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")


if __name__ == '__main__':
    main()
